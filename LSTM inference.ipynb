{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math\n",
    "from tensorflow.contrib.rnn import LSTMCell, DropoutWrapper, MultiRNNCell\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PRSA_lstm:\n",
    "    \n",
    "    def __init__(self, model_to_restore=\"model/lstm-200\"):\n",
    "    \n",
    "        self._input_col_cfg = ['pm25_prev', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'NE', 'NW', 'SE', 'cv']\n",
    "        self._time_steps = 23\n",
    "        num_units = [64, 64]\n",
    "        self._X_min, self._X_max = (np.array([  0.00000000e+00,  -4.00000000e+01,  -1.90000000e+01,\n",
    "                              9.91000000e+02,   4.50000000e-01,   0.00000000e+00,\n",
    "                              0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
    "                              0.00000000e+00,   0.00000000e+00]),\n",
    "                             np.array([  9.94000000e+02,   2.80000000e+01,   4.20000000e+01,\n",
    "                                      1.04600000e+03,   5.65490000e+02,   2.70000000e+01,\n",
    "                                      3.60000000e+01,   1.00000000e+00,   1.00000000e+00,\n",
    "                                      1.00000000e+00,   1.00000000e+00]))\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "\n",
    "        with self._graph.as_default():\n",
    "\n",
    "\n",
    "            self._Xt = tf.placeholder(shape=[1, self._time_steps, 11], dtype=tf.float32)\n",
    "            b_size = tf.shape(self._Xt)[0]\n",
    "\n",
    "            #I do a basic now and look at the graph\n",
    "            lstm_cells = list()\n",
    "            for u in range(len(num_units)):\n",
    "                lstm_cells.append(LSTMCell(num_units=num_units[u], state_is_tuple=True))\n",
    "                                  \n",
    "            lstm_cells = MultiRNNCell(lstm_cells, state_is_tuple=True)\n",
    "            initial_states = lstm_cells.zero_state(b_size, dtype=tf.float32)\n",
    "            outputs, states = tf.nn.dynamic_rnn(lstm_cells, inputs=self._Xt, initial_state=initial_states)\n",
    "\n",
    "            self._fc_final = fully_connected(inputs=outputs[:,-1,:], activation_fn=None, num_outputs=1)\n",
    "            new_saver = tf.train.Saver()\n",
    "        \n",
    "        self._sess = tf.Session(graph=self._graph)    \n",
    "        new_saver.restore(self._sess, model_to_restore)\n",
    "            \n",
    "    def _preprocess(self, data, return_df=False):\n",
    "        assert(np.all(data.columns.values == np.array(['pm2.5', 'DEWP', 'TEMP', 'PRES', 'cbwd', 'Iws', 'Is', 'Ir'])))\n",
    "        \n",
    "        assert(len(data)==self._time_steps+1)\n",
    "        assert(np.all(np.isnan(data[\"pm2.5\"].iloc[0:-1])==False))\n",
    "        #assert(np.isnan(data[\"pm2.5\"].iloc[-1]))\n",
    "               \n",
    "        data[\"pm2.5\"] = data[\"pm2.5\"].shift(1)\n",
    "        data.drop(labels=data.index[0], axis=0,inplace=True)\n",
    "        assert(np.all(np.isnan(data[\"pm2.5\"])==False))\n",
    "        data.rename(columns={\"pm2.5\":\"pm25_prev\"}, inplace=True)\n",
    "        data = pd.concat([data, pd.get_dummies(data.cbwd)], axis=1)\n",
    "        data.drop(labels=[\"cbwd\"], axis=1, inplace=True)\n",
    "   \n",
    "      \n",
    "        cols_to_add = set(self._input_col_cfg) - set(data.columns)\n",
    "        for c in cols_to_add:\n",
    "            data[c] = None\n",
    "        \n",
    "        data = data[self._input_col_cfg]\n",
    "        data.fillna(0, inplace=True)\n",
    "        \n",
    "        assert(data.shape[0]==self._time_steps)\n",
    "        if return_df:\n",
    "            return (data)\n",
    "        else:\n",
    "            return ((data.values-self._X_min)/(self._X_max-self._X_min))\n",
    "        \n",
    "    \n",
    "    def predict(self, data):\n",
    "        X = self._preprocess(data)\n",
    "        X = np.expand_dims(X, axis=0)\n",
    "        return(self._sess.run(self._fc_final, {self._Xt:X})[0][0])\n",
    "     \n",
    "    def __exit__(self):\n",
    "        \n",
    "        self._sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"PRSA_data_2010.1.1-2014.12.31.csv\")\n",
    "data[\"pm25_predicted\"] = 0\n",
    "data = data[np.isnan(data[\"pm2.5\"])==False]\n",
    "\n",
    "data.index = data.apply(lambda x:datetime(x.year, x.month, x.day, x.hour), axis=1)\n",
    "data.drop(labels=[\"year\", \"month\", \"day\", \"hour\", \"No\"], axis=1, inplace=True)\n",
    "\n",
    "ts = pd.date_range(start=data.index.min(), end=data.index.max(), freq=\"H\")\n",
    "data = data.reindex(index=ts, method=\"pad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/lstm-200\n"
     ]
    }
   ],
   "source": [
    "m = PRSA_lstm()\n",
    "data = data.iloc[35029::]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other scenario would be to simply giv ethe first 24 and then replace the one the with the predicted one<br/>\n",
    "so yo need to keep the pm2.5 and call it the original<br/>\n",
    "then get the next one and do a graph based on that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "predicted = 0 \n",
    "#Do the time series indexing out may be\n",
    "while i < len(data)-24:\n",
    "    its = i//((len(data)-24)//100)\n",
    "    \n",
    "    data_test = data.drop(labels=\"pm25_predicted\", axis=1).iloc[i:i+24].copy()\n",
    "    predicted_value = m.predict(data_test)\n",
    "    data.iat[i+23, np.where(data.columns==\"pm25_predicted\")[0][0]] = predicted_value\n",
    "    \n",
    "    print(\"\\r{}{:103}{}\".format(\"|\", \"=\"*its+\"%\"+str(its), \"|\"), end=\" \")\n",
    "    i +=1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[data.pm25_predicted!=0][[\"pm2.5\", \"pm25_predicted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.plot(figsize=[10, 10])\n",
    "#plt.xlim((\"Nov 24 2014\", \"Nov 27 2014\"))\n",
    "          \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
